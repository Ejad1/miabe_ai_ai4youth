# Structure de Sortie du Scrapping

Ce document dÃ©crit l'organisation des donnÃ©es scrapÃ©es pour le projet CampusGPT / MiabÃ© IA.

## Structure des Dossiers

```
scrapped_documents/
â”œâ”€â”€ html_brut/              # Pages HTML brutes tÃ©lÃ©chargÃ©es
â”œâ”€â”€ html_hashes/            # Hash SHA-256 des contenus HTML (fichiers .hash)
â”œâ”€â”€ html_texts/             # Textes extraits des pages HTML
â”œâ”€â”€ converted_html/         # Pages HTML converties en Markdown
â”œâ”€â”€ documents/              # Documents binaires (PDF, DOCX, etc.)
â”œâ”€â”€ document_hashes/        # Hash SHA-256 des documents (fichiers .hash)
â”œâ”€â”€ converted_documents/    # Documents convertis en Markdown
â””â”€â”€ metadata.json           # MÃ©tadonnÃ©es et mapping des fichiers
```

## ğŸ”‘ SystÃ¨me de Nommage

### Fichiers avec Hash d'URL

Tous les fichiers sont nommÃ©s avec le **hash SHA-256 de leur URL** :

- `abc123def456...` â†’ Hash SHA-256 de `https://univ-lome.tg/page.html`
- `xyz789abc123...` â†’ Hash SHA-256 de `https://univ-lome.tg/document.pdf`

### Fichiers de Hash de Contenu

Les hash de contenu sont Ã©galement SHA-256 et stockÃ©s dans des fichiers sÃ©parÃ©s :

- `html_hashes/abc123def456....hash` â†’ Contient le SHA-256 du contenu HTML
- `document_hashes/xyz789abc123....hash` â†’ Contient le SHA-256 du document PDF

## DÃ©duplication Intelligente

### Logique en 2 Ã‰tapes

#### Ã‰tape 1 : VÃ©rification du Contenu
- Calcule le hash SHA-256 du contenu tÃ©lÃ©chargÃ©
- Cherche si ce hash existe dans `*_hashes/`
- **Si trouvÃ©** â†’ SKIP (contenu dÃ©jÃ  scrapÃ© depuis une autre URL)
- **Si non trouvÃ©** â†’ Continue Ã  l'Ã©tape 2

#### Ã‰tape 2 : VÃ©rification de l'URL

- Calcule le hash SHA-256 de l'URL
- Cherche si un fichier avec ce nom existe
- **Si non trouvÃ©** â†’ Nouveau fichier, sauvegarde
- **Si trouvÃ©** â†’ Compare les hash de contenu
  - **Identique** â†’ SKIP (page inchangÃ©e)
  - **DiffÃ©rent** â†’ Supprime l'ancien, sauvegarde le nouveau (mise Ã  jour)

### Avantages

1. Ã‰vite les doublons (mÃªme contenu, URLs diffÃ©rentes)
2. DÃ©tecte les mises Ã  jour (mÃªme URL, contenu modifiÃ©)
3. Ã‰conomise l'espace disque
4. Permet le scrapping incrÃ©mental
5. Garde toujours la version la plus rÃ©cente

## metadata.json

Le fichier `metadata.json` contient le mapping entre les noms hashÃ©s et les informations originales :

```json
{
  "abc123def456": {
    "original_name": "syllabus_math.pdf",
    "url": "https://univ-lome.tg/docs/syllabus_math.pdf",
    "content_hash": "a1b2c3d4e5f6789...xyz",
    "duplicate_of": null,
    "timestamp": "2025-11-05T10:00:00Z"
  }
}
```

### Champs
- `original_name` : Nom original du fichier
- `url` : URL source complÃ¨te
- `content_hash` : Hash SHA-256 du contenu
- `duplicate_of` : `null` si original, sinon hash_name du fichier original
- `timestamp` : Date/heure de scrapping (UTC)

## ğŸ¯ Cas d'Usage

### Premier Scrapping
```
URL1 â†’ tÃ©lÃ©charge â†’ hash contenu â†’ nouveau â†’ sauvegarde tout
```

### Scrapping IncrÃ©mental (mÃªme URL)
```
URL1 â†’ tÃ©lÃ©charge â†’ hash contenu â†’ compare avec ancien
  â†’ Si identique â†’ SKIP
  â†’ Si diffÃ©rent â†’ Supprime ancien + Sauvegarde nouveau
```

### Scrapping de Doublon (URL diffÃ©rente, mÃªme contenu)
```
URL2 â†’ tÃ©lÃ©charge â†’ hash contenu â†’ existe dÃ©jÃ  â†’ SKIP (ne sauvegarde pas)
```
